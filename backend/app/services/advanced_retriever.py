from typing import List, Optional, Dict, Any, Tuple
import logging
from datetime import datetime

from langchain.retrievers import (
    ParentDocumentRetriever,
    MultiQueryRetriever,
    ContextualCompressionRetriever,
    EnsembleRetriever
)
from langchain.retrievers.document_compressors import (
    LLMChainExtractor,
    LLMChainFilter,
    EmbeddingsFilter
)
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.storage import InMemoryStore
from langchain_community.vectorstores import FAISS
from langchain.schema import Document, BaseRetriever
# from langchain.chat_models import ChatOpenAI  # removed
from langchain.prompts import PromptTemplate

from app.core.config import settings
from app.services.vector_service import VectorService
from app.services.llm_service import LLMService

logger = logging.getLogger(__name__)

class AdvancedRetrieverService:
    """é«˜çº§æ£€ç´¢å™¨æœåŠ¡ç±»ï¼Œæ•´åˆå¤šç§æ£€ç´¢ç­–ç•¥"""
    
    def __init__(self, llm: Optional[object] = None):
        self.vector_service = VectorService.get_instance()
        # ä½¿ç”¨ä¸å‘é‡åº“ä¸€è‡´çš„åµŒå…¥æ¨¡å‹ï¼Œç¡®ä¿æ£€ç´¢ç©ºé—´ä¸€è‡´
        self.embeddings = self.vector_service._langchain_embeddings
        
        # LLMç”¨äºæŸ¥è¯¢ç”Ÿæˆå’Œå‹ç¼©
        if llm is not None:
            self.llm = llm
            self.llm_service = None
        else:
            self.llm_service = LLMService()
            self.llm = self.llm_service.get_llm()
        
        # å­˜å‚¨æœåŠ¡
        self.docstore = InMemoryStore()
        
        # æ–‡æœ¬åˆ†å‰²å™¨ - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ¯”ä¾‹
        parent_ratio = getattr(settings, "parent_chunk_ratio", 1.5)
        child_ratio = getattr(settings, "child_chunk_ratio", 0.8)
        self.parent_splitter = RecursiveCharacterTextSplitter(
            chunk_size=int(settings.chunk_size * parent_ratio),  # çˆ¶æ–‡æ¡£å¤§å°
            chunk_overlap=settings.chunk_overlap
        )
        
        self.child_splitter = RecursiveCharacterTextSplitter(
            chunk_size=int(settings.chunk_size * child_ratio),  # å­æ–‡æ¡£å¤§å°
            chunk_overlap=int(settings.chunk_overlap * child_ratio)
        )
        
        # ç¼“å­˜æ£€ç´¢å™¨å®ä¾‹
        self._parent_retriever = None
        self._multi_query_retriever = None
        self._compression_retriever = None
        self._ensemble_retriever = None
    
    def _create_default_llm(self):
        """åˆ›å»ºé»˜è®¤LLMå®ä¾‹ï¼ˆé€šè¿‡LLMServiceï¼‰"""
        service = LLMService()
        return service.get_llm()
    
    def create_parent_document_retriever(self) -> ParentDocumentRetriever:
        """åˆ›å»ºçˆ¶æ–‡æ¡£æ£€ç´¢å™¨"""
        if self._parent_retriever is not None:
            return self._parent_retriever
        
        try:
            # åˆ›å»ºå­æ–‡æ¡£å‘é‡å­˜å‚¨
            child_vectorstore = FAISS.from_texts(
                texts=["åˆå§‹åŒ–æ–‡æœ¬"],
                embedding=self.embeddings
            )
            
            # åˆ›å»ºçˆ¶æ–‡æ¡£æ£€ç´¢å™¨
            self._parent_retriever = ParentDocumentRetriever(
                vectorstore=child_vectorstore,
                docstore=self.docstore,
                child_splitter=self.child_splitter,
                parent_splitter=self.parent_splitter,
                search_kwargs={"k": settings.retrieval_k // 2}
            )
            
            logger.info("çˆ¶æ–‡æ¡£æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
            return self._parent_retriever
            
        except Exception as e:
            logger.error(f"åˆ›å»ºçˆ¶æ–‡æ¡£æ£€ç´¢å™¨å¤±è´¥: {e}")
            raise
    
    def create_multi_query_retriever(self, base_retriever: BaseRetriever) -> MultiQueryRetriever:
        """åˆ›å»ºå¤šæŸ¥è¯¢æ£€ç´¢å™¨"""
        if self._multi_query_retriever is not None:
            return self._multi_query_retriever
        
        try:
            # è‡ªå®šä¹‰æŸ¥è¯¢ç”Ÿæˆæç¤º - æ ¹æ®é…ç½®åŠ¨æ€ç”Ÿæˆ
            query_count = settings.multi_query_num_queries
            query_lines = "\n".join([f"æŸ¥è¯¢{i+1}:" for i in range(query_count)])
            
            query_prompt = PromptTemplate(
                input_variables=["question"],
                template=f"""ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œéœ€è¦ä¸ºç»™å®šçš„é—®é¢˜ç”Ÿæˆå¤šä¸ªä¸åŒçš„æœç´¢æŸ¥è¯¢ã€‚
                
åŸå§‹é—®é¢˜: {{question}}

è¯·ç”Ÿæˆ{query_count}ä¸ªä¸åŒè§’åº¦çš„æœç´¢æŸ¥è¯¢ï¼Œè¿™äº›æŸ¥è¯¢åº”è¯¥èƒ½å¤Ÿå¸®åŠ©æ‰¾åˆ°å›ç­”åŸå§‹é—®é¢˜æ‰€éœ€çš„ä¿¡æ¯ã€‚
æ¯ä¸ªæŸ¥è¯¢åº”è¯¥ä»ä¸åŒçš„è§’åº¦æˆ–ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æ¥è¡¨è¾¾ç›¸åŒçš„ä¿¡æ¯éœ€æ±‚ã€‚

{query_lines}"""
            )
            
            self._multi_query_retriever = MultiQueryRetriever.from_llm(
                retriever=base_retriever,
                llm=self.llm,
                prompt=query_prompt
            )
            
            logger.info("å¤šæŸ¥è¯¢æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
            return self._multi_query_retriever
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå¤šæŸ¥è¯¢æ£€ç´¢å™¨å¤±è´¥: {e}")
            raise
    
    def create_contextual_compression_retriever(self, base_retriever: BaseRetriever) -> ContextualCompressionRetriever:
        """åˆ›å»ºä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨"""
        if self._compression_retriever is not None:
            return self._compression_retriever
        
        try:
            # åˆ›å»ºLLMé“¾æå–å™¨
            compressor = LLMChainExtractor.from_llm(
                llm=self.llm,
                prompt=PromptTemplate(
                    input_variables=["question", "context"],
                    template="""ç»™å®šä»¥ä¸‹ä¸Šä¸‹æ–‡å’Œé—®é¢˜ï¼Œè¯·æå–ä¸é—®é¢˜æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚
                    åªè¿”å›ç›´æ¥ç›¸å…³çš„å†…å®¹ï¼Œå»é™¤æ— å…³ä¿¡æ¯ã€‚
                    
                    é—®é¢˜: {question}
                    
                    ä¸Šä¸‹æ–‡: {context}
                    
                    ç›¸å…³ä¿¡æ¯:"""
                )
            )
            
            self._compression_retriever = ContextualCompressionRetriever(
                base_compressor=compressor,
                base_retriever=base_retriever
            )
            
            logger.info("ä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
            return self._compression_retriever
            
        except Exception as e:
            logger.error(f"åˆ›å»ºä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨å¤±è´¥: {e}")
            raise
    
    def create_ensemble_retriever(self) -> EnsembleRetriever:
        """åˆ›å»ºé›†æˆæ£€ç´¢å™¨ï¼Œç»„åˆå¤šç§æ£€ç´¢ç­–ç•¥"""
        if self._ensemble_retriever is not None:
            return self._ensemble_retriever
        
        try:
            # è·å–åŸºç¡€æ£€ç´¢å™¨
            base_retriever = self.vector_service.vector_store.as_retriever(
                search_type="similarity",
                search_kwargs={"k": settings.retrieval_k}
            )
            
            # åˆ›å»ºå„ç§æ£€ç´¢å™¨
            parent_retriever = self.create_parent_document_retriever()
            multi_query_retriever = self.create_multi_query_retriever(base_retriever)
            compression_retriever = self.create_contextual_compression_retriever(base_retriever)
            
            # åˆ›å»ºé›†æˆæ£€ç´¢å™¨
            self._ensemble_retriever = EnsembleRetriever(
                retrievers=[
                    base_retriever,
                    parent_retriever,
                    multi_query_retriever,
                    compression_retriever
                ],
                weights=settings.ensemble_weights  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æƒé‡
            )
            
            logger.info("é›†æˆæ£€ç´¢å™¨åˆ›å»ºæˆåŠŸ")
            return self._ensemble_retriever
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé›†æˆæ£€ç´¢å™¨å¤±è´¥: {e}")
            raise
    
    def add_documents_to_parent_retriever(self, documents: List[Document]):
        """å‘çˆ¶æ–‡æ¡£æ£€ç´¢å™¨æ·»åŠ æ–‡æ¡£"""
        try:
            parent_retriever = self.create_parent_document_retriever()
            parent_retriever.add_documents(documents)
            logger.info(f"æˆåŠŸå‘çˆ¶æ–‡æ¡£æ£€ç´¢å™¨æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            logger.error(f"å‘çˆ¶æ–‡æ¡£æ£€ç´¢å™¨æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            raise
    
    def search_with_advanced_retriever(self, 
                                     query: str, 
                                     retriever_type: str = "ensemble",
                                     k: int = None) -> List[Document]:
        """ä½¿ç”¨é«˜çº§æ£€ç´¢å™¨è¿›è¡Œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            retriever_type: æ£€ç´¢å™¨ç±»å‹ (ensemble, parent, multi_query, compression)
            k: è¿”å›æ–‡æ¡£æ•°é‡
        
        Returns:
            æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        """
        try:
            k = k or settings.retrieval_k
            
            logger.info(f"ğŸ” é«˜çº§æ£€ç´¢å™¨å¼€å§‹æœç´¢: '{query[:50]}{'...' if len(query) > 50 else ''}'")
            logger.info(f"ğŸ“Š æ£€ç´¢å‚æ•°: k={k}, æ£€ç´¢å™¨ç±»å‹={retriever_type}")
            
            if retriever_type == "ensemble":
                logger.info("ğŸ”§ åˆ›å»ºé›†æˆæ£€ç´¢å™¨...")
                retriever = self.create_ensemble_retriever()
            elif retriever_type == "parent":
                logger.info("ğŸ”§ åˆ›å»ºçˆ¶æ–‡æ¡£æ£€ç´¢å™¨...")
                retriever = self.create_parent_document_retriever()
            elif retriever_type == "multi_query":
                logger.info("ğŸ”§ åˆ›å»ºå¤šæŸ¥è¯¢æ£€ç´¢å™¨...")
                base_retriever = self.vector_service.vector_store.as_retriever(
                    search_kwargs={"k": k}
                )
                retriever = self.create_multi_query_retriever(base_retriever)
            elif retriever_type == "compression":
                logger.info("ğŸ”§ åˆ›å»ºä¸Šä¸‹æ–‡å‹ç¼©æ£€ç´¢å™¨...")
                base_retriever = self.vector_service.vector_store.as_retriever(
                    search_kwargs={"k": k}
                )
                retriever = self.create_contextual_compression_retriever(base_retriever)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ£€ç´¢å™¨ç±»å‹: {retriever_type}")
            
            # æ‰§è¡Œæ£€ç´¢
            logger.info("ğŸ”„ æ‰§è¡Œé«˜çº§æ£€ç´¢...")
            documents = retriever.get_relevant_documents(query)
            
            logger.info(f"ğŸ“‹ åŸå§‹æ£€ç´¢ç»“æœ: {len(documents)} ä¸ªæ–‡æ¡£")
            
            # è®°å½•æ£€ç´¢ç»“æœè¯¦æƒ…
            for i, doc in enumerate(documents[:5]):  # åªè®°å½•å‰5ä¸ªç»“æœ
                doc_id = doc.metadata.get('document_id', 'unknown')
                content_preview = doc.page_content[:100].replace('\n', ' ')
                logger.debug(f"ğŸ“„ ç»“æœ {i+1}: doc_id={doc_id}, content='{content_preview}...'")
            
            logger.info(f"âœ… ä½¿ç”¨ {retriever_type} æ£€ç´¢å™¨æ‰¾åˆ° {len(documents)} ä¸ªç›¸å…³æ–‡æ¡£")
            if len(documents) == 0:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•ç›¸å…³æ–‡æ¡£")
            
            return documents
            
        except Exception as e:
            logger.error(f"âŒ é«˜çº§æ£€ç´¢å™¨æœç´¢å¤±è´¥: {e}")
            return []
    
    def get_retriever_stats(self) -> Dict[str, Any]:
        """è·å–æ£€ç´¢å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "parent_retriever_initialized": self._parent_retriever is not None,
            "multi_query_retriever_initialized": self._multi_query_retriever is not None,
            "compression_retriever_initialized": self._compression_retriever is not None,
            "ensemble_retriever_initialized": self._ensemble_retriever is not None,
            "docstore_size": len(self.docstore.mget(list(self.docstore.yield_keys()))),
            "vector_store_stats": self.vector_service.get_vector_store_stats()
        }
    
    def reset_retrievers(self):
        """é‡ç½®æ‰€æœ‰æ£€ç´¢å™¨å®ä¾‹"""
        self._parent_retriever = None
        self._multi_query_retriever = None
        self._compression_retriever = None
        self._ensemble_retriever = None
        self.docstore = InMemoryStore()
        logger.info("æ‰€æœ‰æ£€ç´¢å™¨å·²é‡ç½®")